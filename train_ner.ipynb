{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00995b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_data as ut\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "tokenizerBERT = BertTokenizer.from_pretrained('pranav-s/MaterialsBERT')\n",
    "modelBERT = BertForMaskedLM.from_pretrained('pranav-s/MaterialsBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6413d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'POLYMER': 1,\n",
    "           'ORGANIC': 2,\n",
    "           'MONOMER': 3,\n",
    "           'PROP_NAME': 4,\n",
    "           'INORGANIC': 5,\n",
    "           'MATERIAL_AMOUNT': 6,\n",
    "           'POLYMER_FAMILY': 7,\n",
    "           'PROP_VALUE': 8,\n",
    "           'O': 0}\n",
    "class NERBERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = modelBERT.base_model\n",
    "        self.linear = nn.Linear(768, len(classes))\n",
    "        \n",
    "    def forward(self, token):\n",
    "        encoder_output= self.bert(token)\n",
    "        linear_output = self.linear(encoder_output.last_hidden_state[0,:,:])\n",
    "        class_output = F.softmax(linear_output, dim=1)\n",
    "        return class_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784af378",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERBERTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb25e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = ut.read_data('train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94aff78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "366bff7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss: 1.42592752\n",
      "epoch:  1  loss: 1.42592382\n",
      "epoch:  2  loss: 1.42592311\n",
      "epoch:  3  loss: 1.42592180\n",
      "epoch:  4  loss: 1.42592156\n",
      "epoch:  5  loss: 1.42592061\n",
      "epoch:  6  loss: 1.42592061\n",
      "epoch:  7  loss: 1.42592025\n",
      "epoch:  8  loss: 1.42592025\n",
      "epoch:  9  loss: 1.42592013\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "train_losses = []\n",
    "for epoch in range(epochs):\n",
    "    for data in data_list[:100]:\n",
    "        token = ut.list2token(tokenizerBERT, data['words'])\n",
    "        prediction = model(token)\n",
    "        target = torch.tensor(ut.cat2digit(classes, data['ner']))\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(loss)\n",
    "    train_losses.append(loss)\n",
    "    print(f'epoch: {epoch:2}  loss: {loss.item():10.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b0be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
